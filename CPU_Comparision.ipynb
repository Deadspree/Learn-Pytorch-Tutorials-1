{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deadspree/Learn-Pytorch-Tutorials-1/blob/main/CPU_Comparision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7orizsRWUnPP",
        "outputId": "35cc0d09-ea8b-4082-c870-3ea3ac801794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorry, CPU only.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJFuSOt6Y42b"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HynZ_pBoVjD-",
        "outputId": "46a286a3-319a-49ff-bec6-b4d872eb7c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 53396347.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 9025581.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 8159831.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 10466445.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "9Z1hdcDzWzO_",
        "outputId": "19a44259-09e9-4a2f-e5e9-d07aadb570d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-shirt/top  Coat  Dress  T-shirt/top\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "print('  '.join(classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfiDYNKFW6GF"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch models inherit from torch.nn.Module\n",
        "class GarmentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GarmentClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GarmentClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2vLv5EAXPG0"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KPiXSmMW7iI"
      },
      "outputs": [],
      "source": [
        "# Optimizers specified in the torch.optim package\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDMqJkOzW_r2"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRpCaQQuXCcB",
        "outputId": "8b9c3b5e-ade8-4ac3-9086-93576e0078ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 1.720481690518558\n",
            "  batch 2000 loss: 0.8049658100046218\n",
            "  batch 3000 loss: 0.6994858302241191\n",
            "  batch 4000 loss: 0.628228137543425\n",
            "  batch 5000 loss: 0.6006192736281082\n",
            "  batch 6000 loss: 0.5550587936062366\n",
            "  batch 7000 loss: 0.5537414792315103\n",
            "  batch 8000 loss: 0.49946430254622826\n",
            "  batch 9000 loss: 0.4670832324244257\n",
            "  batch 10000 loss: 0.48501595871034076\n",
            "  batch 11000 loss: 0.44968435519491323\n",
            "  batch 12000 loss: 0.4629511246710317\n",
            "  batch 13000 loss: 0.4158537682087044\n",
            "  batch 14000 loss: 0.42484443190903404\n",
            "  batch 15000 loss: 0.4358560028716456\n",
            "LOSS train 0.4358560028716456 valid 0.39890310168266296\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 0.4118981971875764\n",
            "  batch 2000 loss: 0.40100779824046184\n",
            "  batch 3000 loss: 0.3873350320075988\n",
            "  batch 4000 loss: 0.3727531568167033\n",
            "  batch 5000 loss: 0.38085243337063\n",
            "  batch 6000 loss: 0.3673221711551887\n",
            "  batch 7000 loss: 0.3709423945321469\n",
            "  batch 8000 loss: 0.34777375837281577\n",
            "  batch 9000 loss: 0.36266838482988534\n",
            "  batch 10000 loss: 0.36379937953899205\n",
            "  batch 11000 loss: 0.3476659527302836\n",
            "  batch 12000 loss: 0.3600232834089693\n",
            "  batch 13000 loss: 0.3454191449523205\n",
            "  batch 14000 loss: 0.3471220523648371\n",
            "  batch 15000 loss: 0.3264580124549975\n",
            "LOSS train 0.3264580124549975 valid 0.34729769825935364\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.34312180479968085\n",
            "  batch 2000 loss: 0.32896623374614864\n",
            "  batch 3000 loss: 0.31529196763604705\n",
            "  batch 4000 loss: 0.32600976752638233\n",
            "  batch 5000 loss: 0.3143362812371488\n",
            "  batch 6000 loss: 0.3255758738521254\n",
            "  batch 7000 loss: 0.30651756408174696\n",
            "  batch 8000 loss: 0.3197704660914715\n",
            "  batch 9000 loss: 0.3238925521489291\n",
            "  batch 10000 loss: 0.3299242832652671\n",
            "  batch 11000 loss: 0.2998173934052975\n",
            "  batch 12000 loss: 0.32178920521736293\n",
            "  batch 13000 loss: 0.32058544429905306\n",
            "  batch 14000 loss: 0.31223098756582474\n",
            "  batch 15000 loss: 0.29903088566223235\n",
            "LOSS train 0.29903088566223235 valid 0.31482425332069397\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.3001611687788536\n",
            "  batch 2000 loss: 0.2880114077274593\n",
            "  batch 3000 loss: 0.26720077687959565\n",
            "  batch 4000 loss: 0.2881242773393751\n",
            "  batch 5000 loss: 0.3000445519833811\n",
            "  batch 6000 loss: 0.2870134330597752\n",
            "  batch 7000 loss: 0.2832880514986464\n",
            "  batch 8000 loss: 0.30674237860875564\n",
            "  batch 9000 loss: 0.29156511308639527\n",
            "  batch 10000 loss: 0.2843842922245094\n",
            "  batch 11000 loss: 0.3062009982276213\n",
            "  batch 12000 loss: 0.2911068712879205\n",
            "  batch 13000 loss: 0.29588294319744457\n",
            "  batch 14000 loss: 0.29556622462587256\n",
            "  batch 15000 loss: 0.29440369533714694\n",
            "LOSS train 0.29440369533714694 valid 0.29754382371902466\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.2996266002568882\n",
            "  batch 2000 loss: 0.26174659216563306\n",
            "  batch 3000 loss: 0.267269389903784\n",
            "  batch 4000 loss: 0.27240946030000124\n",
            "  batch 5000 loss: 0.2579445359215533\n",
            "  batch 6000 loss: 0.2838512947423715\n",
            "  batch 7000 loss: 0.2651544723392399\n",
            "  batch 8000 loss: 0.26020621025226864\n",
            "  batch 9000 loss: 0.2604735428966087\n",
            "  batch 10000 loss: 0.271919387451293\n",
            "  batch 11000 loss: 0.26778297627641584\n",
            "  batch 12000 loss: 0.2695590548505388\n",
            "  batch 13000 loss: 0.2794338956093857\n",
            "  batch 14000 loss: 0.27098632765309183\n",
            "  batch 15000 loss: 0.2778937939326875\n",
            "LOSS train 0.2778937939326875 valid 0.31005027890205383\n"
          ]
        }
      ],
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(validation_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jSsb1CzcXJNl",
        "outputId": "0810734c-046e-4fcc-eece-d877a8d04bfe"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uJ87DfpGX6w3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1GPbuoFVG1fg4Z7CWY698",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}